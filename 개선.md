완전히 동의합니다. 지금 구조가 너무 복잡해졌네요. 처음부터 깔끔하게 재설계해봅시다.

## 🎯 문제점 분석

### 현재 구조의 문제
1. **하나의 레포에 모든 것** - 파싱, 청킹, 임베딩, 검색, MCP 등
2. **언어 혼재** - Python, TypeScript 섞여있음
3. **스크립트 지옥** - 20개 이상의 스크립트 파일
4. **불명확한 경계** - 어디서 무엇을 하는지 불분명

## 🏗️ 클린 아키텍처 제안

### **3개의 독립 서비스로 분리**

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  1. Data ETL    │────▶│  2. Vector DB   │◀────│   3. MCP API    │
│    Service      │     │    Service      │     │    Service      │
└─────────────────┘     └─────────────────┘     └─────────────────┘
     Python                  ChromaDB              Node.js
   (파싱/청킹)              (벡터 저장)           (검색 API)
```

## 📦 레포지토리 분리

### **Repo 1: mcnc-data-etl** (Python)
```
mcnc-data-etl/
├── src/
│   ├── parser.py       # 문서 파싱
│   ├── chunker.py      # 청킹
│   └── embedder.py     # OpenAI 임베딩
├── data/
│   ├── raw/           # 원본 문서
│   └── processed/     # 처리된 데이터
├── requirements.txt
└── main.py            # 실행 스크립트
```

**역할**:
- 문서 파싱 (PDF, DOCX 등)
- 청킹 및 임베딩 생성
- ChromaDB에 업로드

### **Repo 2: mcnc-chromadb** (Docker)
```
mcnc-chromadb/
├── docker-compose.yml
├── Dockerfile
└── README.md
```

**역할**:
- ChromaDB 서버 운영
- 데이터 영속성 관리
- Render/Cloud 배포

### **Repo 3: mcnc-mcp-api** (Node.js)
```
mcnc-mcp-api/
├── src/
│   ├── index.ts        # Express 서버
│   ├── search.ts       # 검색 로직
│   └── mcp-bridge.ts   # MCP <-> HTTP 브릿지
├── package.json
└── tsconfig.json
```

**역할**:
- HTTP API 제공
- MCP 프로토콜 브릿지
- 검색 및 응답 처리

## 🔄 심플한 워크플로우

### **1단계: 데이터 준비** (월 1회)
```bash
# mcnc-data-etl 레포
python main.py --parse --chunk --embed --upload
```

### **2단계: 서비스 실행**
```bash
# ChromaDB (도커 또는 클라우드)
docker run -p 8000:8000 chromadb/chroma

# MCP API 서버
npm start  # Express 서버 실행
```

### **3단계: Claude 연결**
```json
// MCP-over-HTTP 브릿지 사용
{
  "mcpServers": {
    "mcnc": {
      "command": "npx",
      "args": ["mcp-http-bridge", "http://localhost:3000"]
    }
  }
}
```

## 🎨 각 서비스 핵심 코드

### **1. Data ETL (Python)**
```python
# main.py
def process_documents():
    # 1. 파싱
    docs = parse_all_documents("./data/raw")

    # 2. 청킹
    chunks = chunk_documents(docs, chunk_size=400)

    # 3. 임베딩
    embeddings = create_embeddings(chunks)

    # 4. ChromaDB 업로드
    upload_to_chroma(chunks, embeddings)
```

### **2. MCP API (Node.js)**
```typescript
// index.ts
app.post('/search', async (req, res) => {
  const { query } = req.body;

  // 1. 임베딩 생성
  const embedding = await openai.createEmbedding(query);

  // 2. ChromaDB 검색
  const results = await chroma.search(embedding);

  // 3. 응답
  res.json({ results });
});

// MCP 도구
app.post('/mcp/tools/search_knowledge', async (req, res) => {
  // MCP 형식으로 변환
  const results = await search(req.body.query);
  res.json({
    role: "tool",
    content: results
  });
});
```

## ✅ 이 구조의 장점

1. **명확한 책임 분리**
   - ETL: 데이터 처리만
   - ChromaDB: 벡터 저장만
   - MCP API: 검색만

2. **언어별 최적화**
   - Python: 데이터 처리에 최적
   - Node.js: API 서버에 최적

3. **독립적 배포**
   - 각 서비스 독립적으로 업데이트
   - 하나가 죽어도 다른 서비스 영향 없음

4. **간단한 개발**
   - 각 레포 100-200줄 코드
   - 명확한 인터페이스
   - 테스트 용이

## 🚀 구현 우선순위

### **Phase 1: MVP** (1-2일)
1. ChromaDB 도커 실행
2. 간단한 Python ETL 스크립트
3. Express API 서버 (검색만)

### **Phase 2: MCP 연동** (1일)
4. MCP-HTTP 브릿지 구현
5. Claude Desktop 연결

### **Phase 3: 개선** (지속적)
6. ETL 파이프라인 개선
7. 검색 품질 향상
8. 모니터링 추가

## 💡 핵심 결정사항

**Q: 지금 있는 코드는?**
A: 재사용 가능한 핵심 로직만 추출 (파서, 청킹 알고리즘)

**Q: 레포 분리 시점?**
A: 지금 바로. 각각 새로 시작

**Q: 개발 복잡도?**
A: 각 서비스 200줄 이내로 제한

이렇게 단순하게 재구성하는 것 어떠신가요?